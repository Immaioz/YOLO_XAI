{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcBTuzQQtAo4",
        "outputId": "f8a50480-a452-42ef-abed-ad333e97af5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLO_XAI'...\n",
            "remote: Enumerating objects: 1740, done.\u001b[K\n",
            "remote: Counting objects: 100% (415/415), done.\u001b[K\n",
            "remote: Compressing objects: 100% (313/313), done.\u001b[K\n",
            "remote: Total 1740 (delta 94), reused 414 (delta 94), pack-reused 1325\u001b[K\n",
            "Receiving objects: 100% (1740/1740), 1.17 GiB | 21.56 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n",
            "Updating files: 100% (2680/2680), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Immaioz/YOLO_XAI.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddt_96mVttJS",
        "outputId": "0d840a05-21a8-471a-d1d1-47698096fb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLO_XAI\n"
          ]
        }
      ],
      "source": [
        "%cd YOLO_XAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ToTYI6euYTX",
        "outputId": "f9ba0276-0033-438b-d4f6-1f056497b746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Ultralytics\n",
            "  Downloading ultralytics-8.0.188-py3-none-any.whl (615 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/615.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/615.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m614.4/615.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (1.11.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from Ultralytics) (9.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->Ultralytics) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->Ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->Ultralytics) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->Ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->Ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->Ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->Ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->Ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Ultralytics) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Ultralytics) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->Ultralytics) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->Ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->Ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->Ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->Ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->Ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->Ultralytics) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->Ultralytics) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->Ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->Ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->Ultralytics) (1.3.0)\n",
            "Installing collected packages: Ultralytics\n",
            "Successfully installed Ultralytics-8.0.188\n"
          ]
        }
      ],
      "source": [
        "!pip install Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XloWnTsVuhzH",
        "outputId": "728b52bb-befa-4adc-bea8-5478e04f1732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install ttach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78slzL_JuMqt"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from ultralytics import YOLO\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "from yolo_cam.eigen_cam import EigenCAM\n",
        "from yolo_cam.utils.image import show_cam_on_image, scale_cam_image\n",
        "import random\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5vs2K37uNOL"
      },
      "outputs": [],
      "source": [
        "def parse_detections(detections):\n",
        "    boxes, colors, names = [], [], []\n",
        "\n",
        "    for i in range(len(detections[\"xmin\"])):\n",
        "        confidence = float(detections[\"confidence\"][i])\n",
        "        if confidence < 0.2:\n",
        "            continue\n",
        "        xmin = int(float(detections[\"xmin\"][i]))\n",
        "        ymin = int(float(detections[\"ymin\"][i]))\n",
        "        xmax = int(float(detections[\"xmax\"][i]))\n",
        "        ymax = int(float(detections[\"ymax\"][i]))\n",
        "        name = detections[\"name\"][i]\n",
        "        category = int(detections[\"class\"][i])\n",
        "        color = COLORS[category]\n",
        "\n",
        "        boxes.append((xmin, ymin, xmax, ymax))\n",
        "        colors.append(color)\n",
        "        names.append(name)\n",
        "    return boxes, colors, names\n",
        "def draw_detections(boxes, colors, names, img):\n",
        "    for box, color, name in zip(boxes, colors, names):\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        cv2.rectangle(\n",
        "            img,\n",
        "            (xmin, ymin),\n",
        "            (xmax, ymax),\n",
        "            color,\n",
        "            2)\n",
        "\n",
        "        cv2.putText(img, name, (xmin, ymin - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,\n",
        "                    lineType=cv2.LINE_AA)\n",
        "    return img\n",
        "def renormalize_cam_in_bounding_boxes(boxes, colors, names, image_float_np, grayscale_cam):\n",
        "    \"\"\"Normalize the CAM to be in the range [0, 1]\n",
        "    inside every bounding boxes, and zero outside of the bounding boxes. \"\"\"\n",
        "    renormalized_cam = np.zeros(grayscale_cam.shape, dtype=np.float32)\n",
        "    for x1, y1, x2, y2 in boxes:\n",
        "        renormalized_cam[y1:y2, x1:x2] = scale_cam_image(grayscale_cam[y1:y2, x1:x2].copy())\n",
        "    renormalized_cam = scale_cam_image(renormalized_cam)\n",
        "    eigencam_image_renormalized = show_cam_on_image(image_float_np, renormalized_cam, use_rgb=True)\n",
        "    image_with_bounding_boxes = draw_detections(boxes, colors, names, eigencam_image_renormalized)\n",
        "    return image_with_bounding_boxes\n",
        "def printout(outputs):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(outputs)):\n",
        "        ax = plt.subplot(1, 4, i + 1)\n",
        "        plt.imshow(outputs[i] /255, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "def get_image(image_path):\n",
        "    img = np.array(Image.open(image_path))\n",
        "    img = cv2.resize(img, (640, 640))\n",
        "    return img\n",
        "def camtest(image_path):\n",
        "    img = get_image(image_path)\n",
        "    rgb_img = img.copy()\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    results = model([rgb_img], verbose=False)\n",
        "    boxes = results[0].boxes\n",
        "    columns = ['xmin', 'ymin',\t'xmax', 'ymax',\t'confidence', 'class', 'name']\n",
        "    bbox = boxes.xyxy[0].cpu().numpy()\n",
        "    conf = float(boxes.conf.cpu().numpy())\n",
        "    cls = int(boxes.cls[0])\n",
        "    name = (results[0].names[int(boxes.cls[0])])\n",
        "    print(\"Confidence:\", conf)\n",
        "    print(\"Class: \", name)\n",
        "    data = np.array([bbox[0],bbox[1],bbox[2],bbox[3], conf, cls, name ])\n",
        "    detections = pd.DataFrame([data], columns=columns)\n",
        "    boxes, colors, names = parse_detections(detections)\n",
        "    detection = results[0].plot()\n",
        "    cam = EigenCAM(model, target_layers)\n",
        "    grayscale_cam = cam(rgb_img)[0, :, :]\n",
        "    g_scale = np.stack([grayscale_cam] * 3, axis=2)\n",
        "    g_scale = np.array(g_scale) *255\n",
        "    cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
        "    renormalized_cam_image = renormalize_cam_in_bounding_boxes(boxes, colors, names, img, grayscale_cam)\n",
        "    return detection, cam_image, g_scale, renormalized_cam_image\n",
        "\n",
        "def replacepixel(img, mask, percentile_value, task):\n",
        "    mask = mask *255\n",
        "    mask = mask.astype(np.uint8)\n",
        "    image = Image.fromarray(img)\n",
        "    mask = Image.fromarray(mask)\n",
        "    # percentile_value = 100 - percentile_value\n",
        "    mask_intensity = np.percentile(mask, percentile_value)\n",
        "    # Get pixel access objects\n",
        "    pixel_data = image.load()\n",
        "    mask_data = mask.load()\n",
        "    pixel_data = image.load()\n",
        "    mask_data = mask.load()\n",
        "    modified_mask = mask.copy()\n",
        "    modified_mask_data = modified_mask.load()\n",
        "    width, height = image.size\n",
        "    mask_intensity_values = [(mask_r + mask_g + mask_b) / 3 for mask_r, mask_g, mask_b in mask.getdata()]\n",
        "    if (task == 'mean'):\n",
        "        mean_r = np.mean(img[:, :, 0])\n",
        "        mean_g = np.mean(img[:, :, 1])\n",
        "        mean_b = np.mean(img[:, :, 2])\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            mask_intensity_value = mask_intensity_values[y * width + x]\n",
        "\n",
        "            if mask_intensity_value <= mask_intensity:\n",
        "                if(task == 'random'):\n",
        "                    new_r = random.randint(0, 255)\n",
        "                    new_g = random.randint(0, 255)\n",
        "                    new_b = random.randint(0, 255)\n",
        "                    modified_mask_data[x, y] = (new_r, new_g, new_b)\n",
        "                    pixel_data[x, y] = (new_r, new_g, new_b) #random\n",
        "                elif(task == 'mean'):\n",
        "                    pixel_data[x, y] = (int(mean_r), int(mean_g), int(mean_b)) #mean\n",
        "                elif(task == \"remove\"):\n",
        "                    r, g, b = pixel_data[x, y]\n",
        "                    mask_r, mask_g, mask_b = mask_data[x, y]\n",
        "\n",
        "                    new_r = r * (mask_r / 255)\n",
        "                    new_g = g * (mask_g / 255)\n",
        "                    new_b = b * (mask_b / 255)\n",
        "                    modified_mask_data[x, y] = (int(new_r), int(new_g), int(new_b))\n",
        "                    pixel_data[x, y] = (int(new_r), int(new_g), int(new_b))\n",
        "\n",
        "    # Convert the modified Pillow Image back to a numpy array\n",
        "    modified_image = np.array(image)\n",
        "    modified_mask = np.array(modified_mask)\n",
        "    return modified_image, modified_mask\n",
        "\n",
        "def perturbation(img, mask, percentile, task, bbox, cls, model):\n",
        "    results = model(img, verbose=False, max_det=1)\n",
        "    boxes = results[0].boxes\n",
        "    original = results[0].plot()\n",
        "    conf = float(boxes.conf.cpu().numpy())\n",
        "    # data = results[0].boxes.data.cpu().numpy()\n",
        "    # print(data)\n",
        "    if(task == \"remove\"):\n",
        "        perturbed = img * mask\n",
        "        #perturbed, _ = replacepixel(img, mask, percentile, task)\n",
        "    if(task == \"mean\"):\n",
        "        perturbed, _ = replacepixel(img, mask, percentile, task)\n",
        "    if(task == \"random\"):\n",
        "        perturbed, _ = replacepixel(img, mask, percentile, task)\n",
        "    results = model([perturbed], max_det=1, classes = cls)\n",
        "    if len(results[0].boxes) != 0:\n",
        "        iou = calculate_iou(bbox,results[0].boxes.xyxy[0].cpu().numpy())\n",
        "        # data = results[0].boxes.data.cpu().numpy()\n",
        "        # print(data)\n",
        "        new = results[0].plot()\n",
        "        boxes = results[0].boxes\n",
        "        conf_incr =  float(boxes.conf.cpu().numpy())\n",
        "        out = np.stack((original, new), axis=0)\n",
        "        return out, conf_incr, iou\n",
        "    else:\n",
        "        return None, None, None\n",
        "\n",
        "def invert_grayscale_image(image):\n",
        "    # Calculate the maximum pixel value for the grayscale image (usually 255 for 8-bit images)\n",
        "    max_pixel_value = np.max(image)\n",
        "\n",
        "    # Invert the image by subtracting each pixel value from the maximum\n",
        "    inverted_image = max_pixel_value - image\n",
        "\n",
        "    return inverted_image\n",
        "\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    # Convert XYXY format to (x1, y1, x2, y2) format\n",
        "    x1_box1, y1_box1, x2_box1, y2_box1 = box1\n",
        "    x1_box2, y1_box2, x2_box2, y2_box2 = box2\n",
        "\n",
        "    # Calculate the area of each bounding box\n",
        "    area_box1 = (x2_box1 - x1_box1) * (y2_box1 - y1_box1)\n",
        "    area_box2 = (x2_box2 - x1_box2) * (y2_box2 - y1_box2)\n",
        "\n",
        "    # Calculate the coordinates of the intersection box\n",
        "    x1_intersection = max(x1_box1, x1_box2)\n",
        "    y1_intersection = max(y1_box1, y1_box2)\n",
        "    x2_intersection = min(x2_box1, x2_box2)\n",
        "    y2_intersection = min(y2_box1, y2_box2)\n",
        "\n",
        "    # Calculate the area of the intersection box\n",
        "    if x1_intersection < x2_intersection and y1_intersection < y2_intersection:\n",
        "        area_intersection = (x2_intersection - x1_intersection) * (y2_intersection - y1_intersection)\n",
        "    else:\n",
        "        area_intersection = 0.0\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = area_intersection / (area_box1 + area_box2 - area_intersection)\n",
        "\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks4sDBEkum_H"
      },
      "outputs": [],
      "source": [
        "def acquire(img, model, layers):\n",
        "    img = cv2.resize(img, (640, 640))\n",
        "    rgb_img = img.copy()\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    results = model(rgb_img, verbose=False, max_det= 1)\n",
        "    if  len(results[0].boxes) == 0:\n",
        "        return None, None, None, None, None, None, False\n",
        "    else:\n",
        "        boxes = results[0].boxes\n",
        "        columns = ['xmin', 'ymin',\t'xmax', 'ymax',\t'confidence', 'class', 'name']\n",
        "        bbox = boxes.xyxy[0].cpu().numpy()\n",
        "        conf = float(boxes.conf.cpu().numpy())\n",
        "        cls = int(boxes.cls[0])\n",
        "        name = (results[0].names[int(boxes.cls[0])])\n",
        "        data = np.array([bbox[0],bbox[1],bbox[2],bbox[3], conf, cls, name ])\n",
        "        detections = pd.DataFrame([data], columns=columns)\n",
        "        boxes, colors, names = parse_detections(detections)\n",
        "        cam = EigenCAM(model, layers)\n",
        "        grayscale_cam = np.squeeze(cam(rgb_img), axis=0)\n",
        "        inverted_image = invert_grayscale_image(grayscale_cam)\n",
        "        inv = np.stack([inverted_image] * 3, axis=2)\n",
        "        g_scale = np.stack([grayscale_cam] * 3, axis=2)\n",
        "        return g_scale, inv,  rgb_img, bbox, cls, conf, True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ9V4irFunBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8cb175f-9502-4ff3-e292-5fc26be476c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing files: 100%|██████████| 200/200 [00:05<00:00, 34.48it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define the directory path where your images are located\n",
        "image_dir = 'utils/dataset/subset/05_Yatch'\n",
        "\n",
        "# Initialize an empty list to store the image objects\n",
        "image_list = {}\n",
        "\n",
        "# Loop through the files in the directory\n",
        "for filename in tqdm(os.listdir(image_dir), desc=\"Processing files\"):\n",
        "    # Check if the file is an image (you can add more extensions if needed)\n",
        "    if filename.endswith(('.jpg')):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        # Open the image using Pillow (PIL)\n",
        "        image = np.array(Image.open(file_path))\n",
        "        # Append the image object to the list\n",
        "        image_list[filename]=image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSwNWQEDuxAo"
      },
      "outputs": [],
      "source": [
        "modelVis = YOLO('models/VisibleModel/weights/best.pt')\n",
        "modelIR = YOLO('models/IRModel/weights/best.pt')\n",
        "target_layers_vis = [modelVis.model.model[-3]]\n",
        "target_layers_ir = [modelIR.model.model[-3]]\n",
        "COLORS = np.random.uniform(0, 255, size=(len(modelVis.names), 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def normalize(img_array):\n",
        "  normalized_input = (img_array - np.amin(img_array)) / (np.amax(img_array) - np.amin(img_array))\n",
        "  return 2*normalized_input-1\n",
        "\n",
        "\n",
        "def HA_clip(img, heatmap):\n",
        "  HA = img*heatmap\n",
        "  return np.clip(HA, -1,1)"
      ],
      "metadata": {
        "id": "Y9TC8hS_fwQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_layer(model,rgb_img):\n",
        "  u = 0\n",
        "  layers=[]\n",
        "  for i in range(16,1,-1):\n",
        "      target_layers = [model.model.model[-(i)]]\n",
        "      cam = EigenCAM(model, target_layers)\n",
        "      grayscale_cam = cam(rgb_img)[0, :]\n",
        "      # cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
        "      #print(cam_image.shape)\n",
        "      u += 1\n",
        "      #print(u)\n",
        "      layers.append(grayscale_cam)\n",
        "  return layers\n"
      ],
      "metadata": {
        "id": "orGr2bNS7Q99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layers={}\n",
        "# i=0\n",
        "# # Assuming you have a list of images called image_list\n",
        "# # for i in range(len(image_list)):\n",
        "# #   if \"Cam1\" in list(image_list.keys())[i] or \"Cam2\" in list(image_list.keys())[i]:\n",
        "# #     print(list(image_list.keys())[i])\n",
        "# for i in tqdm(range(len(image_list)), desc=\"Processing\"):\n",
        "#     conf_tot = []\n",
        "#     IoU_tot = []\n",
        "#     if \"Cam1\" in list(image_list.keys())[i] or \"Cam2\" in list(image_list.keys())[i]:\n",
        "#       model = modelVis\n",
        "#       layer = target_layers_vis\n",
        "#       name = list(image_list.keys())[i]\n",
        "#     else:\n",
        "#       model = modelIR\n",
        "#       layer = target_layers_ir\n",
        "#       name = list(image_list.keys())[i]\n",
        "\n",
        "#     image = list(image_list.values())[i]\n",
        "#     gray, inv, image, box, classes, conf, x = acquire(image, model, layer)\n",
        "#     # conf_initial[name] = conf\n",
        "\n",
        "#     if x:\n",
        "#         heatmaps = test_layer(model, image)\n",
        "#     layers[name] = (heatmaps)\n",
        "# import pickle\n",
        "\n",
        "# # Specify the file path where you want to save the dictionary\n",
        "# file_path = '00_layers.pkl'\n",
        "\n",
        "# # Open the file in binary write ('wb') mode\n",
        "# with open(file_path, 'wb') as file:\n",
        "#     # Serialize and save the dictionary using pickle.dump\n",
        "#     pickle.dump(layers, file)\n",
        "\n",
        "# print(f\"Dictionary saved to {file_path}\")\n"
      ],
      "metadata": {
        "id": "4F2j_vbj8BjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_tot_all_images = {}\n",
        "IoU_tot_all_images = {}\n",
        "conf_initial = {}\n",
        "heatmap = {}\n",
        "i=0\n",
        "# Assuming you have a list of images called image_list\n",
        "# for i in range(len(image_list)):\n",
        "#   if \"Cam1\" in list(image_list.keys())[i] or \"Cam2\" in list(image_list.keys())[i]:\n",
        "#     print(list(image_list.keys())[i])\n",
        "for i in tqdm(range(len(image_list)), desc=\"Processing\"):\n",
        "    conf_tot = []\n",
        "    IoU_tot = []\n",
        "    if \"Cam1\" in list(image_list.keys())[i] or \"Cam2\" in list(image_list.keys())[i]:\n",
        "      model = modelVis\n",
        "      layers = target_layers_vis\n",
        "      name = list(image_list.keys())[i]\n",
        "    else:\n",
        "      model = modelIR\n",
        "      layers = target_layers_ir\n",
        "      name = list(image_list.keys())[i]\n",
        "\n",
        "    image = list(image_list.values())[i]\n",
        "    gray, inv, image, box, classes, conf, x = acquire(image, model, layers)\n",
        "    if x:\n",
        "      conf_initial[name] = conf\n",
        "      x_norm = normalize(image)\n",
        "      h_norm = normalize(inv)\n",
        "      HA = HA_clip(x_norm, h_norm)\n",
        "      output_array = ((HA + 1) / 2) * 255\n",
        "\n",
        "      # Round the values to integers if needed\n",
        "      output_array = np.round(output_array).astype(int)\n",
        "\n",
        "      results = model(output_array, verbose=False, max_det= 1, classes=classes)\n",
        "      if  len(results[0].boxes) == 0:\n",
        "          conf_tot.append(-1)\n",
        "          IoU_tot.append(0)\n",
        "      else:\n",
        "          boxes = results[0].boxes\n",
        "          columns = ['xmin', 'ymin',\t'xmax', 'ymax',\t'confidence', 'class', 'name']\n",
        "          bbox = boxes.xyxy[0].cpu().numpy()\n",
        "          conf_inc = float(boxes.conf.cpu().numpy())\n",
        "          iou = calculate_iou(box,bbox)\n",
        "          conf_tot.append(conf_inc)\n",
        "          IoU_tot.append(iou)\n",
        "    else:\n",
        "      conf_tot.append(None)\n",
        "      IoU_tot.append(None)\n",
        "\n",
        "    heatmap[name] = (gray)\n",
        "    conf_tot_all_images[name] = (conf_tot)\n",
        "    IoU_tot_all_images[name] = (IoU_tot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YYjNhVtmp8J",
        "outputId": "ce6d28c3-4724-4a74-cb4e-0bae79ae8230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 200/200 [00:33<00:00,  5.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE69jMvSum8P"
      },
      "outputs": [],
      "source": [
        "# conf_tot_all_images = {}\n",
        "# IoU_tot_all_images = {}\n",
        "# conf_initial = {}\n",
        "# heatmap = {}\n",
        "# i=0\n",
        "# # Assuming you have a list of images called image_list\n",
        "# # for i in range(len(image_list)):\n",
        "# #   if \"Cam1\" in list(image_list.keys())[i] or \"Cam2\" in list(image_list.keys())[i]:\n",
        "# #     print(list(image_list.keys())[i])\n",
        "# for i in tqdm(range(len(image_list)), desc=\"Processing\"):\n",
        "#     conf_tot = []\n",
        "#     IoU_tot = []\n",
        "#     if \"Cam1\" in list(image_list.keys())[i] or \"Cam2\" in list(image_list.keys())[i]:\n",
        "#       model = modelVis\n",
        "#       layers = target_layers_vis\n",
        "#       name = list(image_list.keys())[i]\n",
        "#     else:\n",
        "#       model = modelIR\n",
        "#       layers = target_layers_ir\n",
        "#       name = list(image_list.keys())[i]\n",
        "\n",
        "#     image = list(image_list.values())[i]\n",
        "#     gray, inv, image, box, classes, conf, x = acquire(image, model, layers)\n",
        "#     conf_initial[name] = conf\n",
        "\n",
        "#     if x:\n",
        "#       for i in range (0,101,5):\n",
        "#         out, conf_inc, iou = perturbation(image, gray, i, \"mean\", box, classes, model)\n",
        "#         if out is not None:\n",
        "#             # print(\"Confidence increase: \", conf_inc)\n",
        "#             # print(\"Intersection over Union: \", iou)\n",
        "#             conf_tot.append(conf_inc)\n",
        "#             IoU_tot.append(iou)\n",
        "\n",
        "#         else:\n",
        "#             conf_tot.append(-1)\n",
        "#             IoU_tot.append(0)\n",
        "#         # out, conf_inc, iou = perturbation(image, inv, 50, \"remove\", box, classes, model)\n",
        "#         # if out is not None:\n",
        "#         #     # print(\"Confidence increase: \", conf_inc)\n",
        "#         #     # print(\"Intersection over Union: \", iou)\n",
        "#         #     conf_tot.append(conf_inc)\n",
        "#         #     IoU_tot.append(iou)\n",
        "\n",
        "#         # else:\n",
        "#         #     conf_tot.append(-1)\n",
        "#         #     IoU_tot.append(0)\n",
        "#     heatmap[name] = (gray)\n",
        "#     conf_tot_all_images[name] = (conf_tot)\n",
        "#     IoU_tot_all_images[name] = (IoU_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJuB6WF4TNE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597425b3-991a-4849-fedb-2a3b50e01db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary saved to 05_conf_tot.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "# Specify the file path where you want to save the dictionary\n",
        "file_path = '05_conf_tot.pkl'\n",
        "\n",
        "# Open the file in binary write ('wb') mode\n",
        "with open(file_path, 'wb') as file:\n",
        "    # Serialize and save the dictionary using pickle.dump\n",
        "    pickle.dump(conf_tot_all_images, file)\n",
        "\n",
        "print(f\"Dictionary saved to {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYzld4KYTTTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f79da89-e641-45aa-8945-526f8f86fc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary saved to 05_iou_tot.pkl\n"
          ]
        }
      ],
      "source": [
        "# Specify the file path where you want to save the dictionary\n",
        "file_path = '05_iou_tot.pkl'\n",
        "# Open the file in binary write ('wb') mode\n",
        "with open(file_path, 'wb') as file:\n",
        "    # Serialize and save the dictionary using pickle.dump\n",
        "    pickle.dump(IoU_tot_all_images, file)\n",
        "\n",
        "print(f\"Dictionary saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK8pau0LTTM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88cbb836-15f1-46d6-f216-4b4a0dd959c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary saved to 05_initial_conf.pkl\n"
          ]
        }
      ],
      "source": [
        "# Specify the file path where you want to save the dictionary\n",
        "file_path = '05_initial_conf.pkl'\n",
        "\n",
        "# Open the file in binary write ('wb') mode\n",
        "with open(file_path, 'wb') as file:\n",
        "    # Serialize and save the dictionary using pickle.dump\n",
        "    pickle.dump(conf_initial, file)\n",
        "\n",
        "print(f\"Dictionary saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Specify the file path where you want to save the dictionary\n",
        "# file_path = '00_heatmaps.pkl'\n",
        "\n",
        "# # Open the file in binary write ('wb') mode\n",
        "# with open(file_path, 'wb') as file:\n",
        "#     # Serialize and save the dictionary using pickle.dump\n",
        "#     pickle.dump(heatmap, file)\n",
        "\n",
        "# print(f\"Dictionary saved to {file_path}\")"
      ],
      "metadata": {
        "id": "zvHdtJmUlU-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo1EEP2sTykF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "046b837f-65b9-40db-a81f-d70c1ce8d744"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4eb1f7aa-19c8-46fa-82d6-227c4787800e\", \"05_conf_tot.pkl\", 8632)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49afead4-0a7d-4708-92dd-c1d06aa0868c\", \"05_initial_conf.pkl\", 5788)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_63362981-faad-43bc-9f5b-f0a447eb3f6f\", \"05_iou_tot.pkl\", 8750)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('05_conf_tot.pkl')\n",
        "files.download('05_initial_conf.pkl')\n",
        "files.download('05_iou_tot.pkl')\n",
        "# files.download('00_heatmaps.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cB1ewKA2MPDN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}